import gc
import math
import typing

import numpy
import pandas
import torch.nn
from torch import Tensor
from tqdm import tqdm
from pandas import DataFrame
from torch.nn import MSELoss
from torch.optim import Optimizer
from torch.utils.data import DataLoader

from Const import *
from Model import Model
from ModelDataSet import ModelDataSet

DATE_KEY = "æ—¥æœŸ"
TIME_KEY = "æ—¶åˆ»"
FIXED_DATETIME_KEY = "datetime"

DATA_LENGTH = 50
PREDICT_LENGTH = 10
VERIFY_SPLIT = 0.8

BATCH_SIZE = 64
EPOCHS = 20
LOSS_RATE = 1e-3


def loadDataFrame(path: str) -> DataFrame:
    """è¯»å–æ•°æ®å’Œå½’ä¸€åŒ–"""
    dataframe: DataFrame = pandas.read_csv(path, sep=";", na_values="?")
    dataframe[FIXED_DATETIME_KEY] = pandas.to_datetime(dataframe[DATE_KEY] + " " + dataframe[TIME_KEY], dayfirst=True)
    dataframe.drop(columns=["æ—¥æœŸ", "æ—¶åˆ»", "ç”µå‹", "ç”µæµ", "å¨æˆ¿ç”¨ç”µåŠŸç‡", "æ´—è¡£é—´ç”¨ç”µåŠŸç‡"], inplace=True)
    dataframe.set_index(FIXED_DATETIME_KEY, inplace=True)
    # æå–æ—¶é—´ç‰¹å¾ï¼ŒGPT è¯´è¿™èƒ½è®©æ¨¡å‹æ›´å¥½çš„ç†è§£å‘¨æœŸæ€§
    hour = dataframe["hour"] = dataframe.index.hour
    minute = dataframe["minute"] = dataframe.index.minute
    dayOfWeek = dataframe["dayOfWeek"] = dataframe.index.dayofweek
    dataframe["hourSin"] = numpy.sin(2 * PI * hour / 24)
    dataframe["hourCos"] = numpy.cos(2 * PI * hour / 24)
    dataframe["minuteSin"] = numpy.sin(2 * PI * minute / 60)
    dataframe["minuteCos"] = numpy.cos(2 * PI * minute / 60)
    dataframe["dayOfWeekSin"] = numpy.sin(2 * PI * dayOfWeek / 7)
    dataframe["dayOfWeekCos"] = numpy.cos(2 * PI * dayOfWeek / 7)
    dataframe = dataframe.astype(DATA_TYPE)
    dataframe.interpolate(inplace=True)  # å­©å­ä»¬æˆ‘æ‰çŸ¥é“pandaå¯ä»¥è‡ªåŠ¨è¡¥å……ç¼ºå¤±å€¼ğŸ‘
    return dataframe


def generateSeq(vector: Matrix, targetIndex: int) -> tuple[Array[Matrix], Array[Matrix]]:
    """
    æˆ‘ä¸çŸ¥é“è¿™ä¹ˆå†™æ»‘åŠ¨çª—å£æ˜¯ä¸æ˜¯å†…å­˜å ç”¨ä¼šéå¸¸é«˜ğŸ¤”
    å®æµ‹å ç”¨1GBå·¦å³ï¼Œå¯ä»¥æ¥å—
    """
    inData: list[Matrix] = []
    outData: list[Matrix] = []
    for i in tqdm(range(len(vector) - DATA_LENGTH - PREDICT_LENGTH), leave=True, desc="Generate Sequences", ncols=100):
        dataBegin = i
        predictBegin = i + DATA_LENGTH
        inData.append(vector[dataBegin:dataBegin + DATA_LENGTH])
        outData.append(vector[predictBegin:predictBegin + PREDICT_LENGTH, targetIndex])
    return typing.cast(tuple[Array[Matrix], Array[Matrix]], (numpy.array(inData), numpy.array(outData)))


def train(model: Model, trainLoader: DataLoader, verifyLoader: DataLoader, epochs: int, lossRate: float):
    device: torch.device = torch.device("cpu")
    model.to(device)
    optimizer: Optimizer = torch.optim.Adam(model.parameters(), lr=lossRate)
    lossMethod: MSELoss = MSELoss()

    with tqdm(total=epochs * 2, leave=True, ncols=100) as progress:
        for i in range(epochs):
            progress.set_description(f"Train Model (Epoch: {i + 1})")

            # train
            model.train()
            progressTL = tqdm(total=len(trainLoader), ncols=100)
            trainLoss = 0.0
            for inBatch, outBatch in trainLoader:
                # check
                assert not torch.isnan(inBatch).any()
                assert not torch.isinf(inBatch).any()
                assert not torch.isnan(outBatch).any()
                assert not torch.isinf(outBatch).any()

                progressTL.set_description(f"Train Loss (Loss: {trainLoss:.4f})")

                inBatch, outBatch = inBatch.to(device), outBatch.to(device)
                pred = model(inBatch)
                loss: Tensor = lossMethod(pred, outBatch)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                trainLoss += loss.item()

                progressTL.update()
            progress.update()

            # verify
            model.eval()
            progressVL = tqdm(total=len(trainLoader), ncols=100)
            verifyLoss = 0.0
            with torch.no_grad():
                for inBatch, outBatch in verifyLoader:
                    progressVL.set_description(f"Verify Loss (Loss: {verifyLoss:.4f})")

                    inBatch, outBatch = inBatch.to(device), outBatch.to(device)
                    pred = model(inBatch)
                    loss: Tensor = lossMethod(pred, outBatch)
                    verifyLoss += loss.item()
            verifyLoss /= len(verifyLoader)

            progressTL.close()
            progressVL.close()
            progress.update()
            tqdm.write(f"Epoch {i + 1}/{epochs}, Train Loss: {trainLoss:.4f}, Verify Loss: {verifyLoss:.4f}.")


def predict(model: Model, inputSeq: Matrix) -> Vector:
    model.eval()
    device: torch.device = next(model.parameters()).device
    with torch.no_grad():
        input_seq = torch.tensor(inputSeq, dtype=DTYPE).unsqueeze(0).to(device)
        pred: Tensor = model(input_seq)
        return typing.cast(Vector, pred.cpu().numpy().flatten())


def main():
    tqdm.write("åˆå§‹åŒ–æ•°æ®...")
    dataframe = loadDataFrame("../household_power_consumption.txt")
    targetIndex: int = dataframe.columns.get_loc("æ€»åŠŸç‡")  # é¢„æµ‹çš„ç›®æ ‡åˆ—
    matrix: Matrix = typing.cast(Matrix, dataframe.values)
    assert not numpy.isnan(matrix).any()
    assert not numpy.isinf(matrix).any()
    del dataframe  # èŠ‚çœå†…å­˜

    gc.collect()
    inData, outData = generateSeq(matrix, targetIndex)  # ç”¨äºè®­ç»ƒ
    del matrix

    # å‡†å¤‡è®­ç»ƒæ•°æ®
    tqdm.write("å‡†å¤‡è®­ç»ƒæ•°æ®...")
    gc.collect()
    assert len(inData) == len(outData)
    split = int(len(inData) * VERIFY_SPLIT)
    trainData = ModelDataSet(inData[:split], outData[:split])
    verifyData = ModelDataSet(inData[split:], outData[split:])
    trainLoader = DataLoader(trainData, batch_size=BATCH_SIZE, shuffle=True)
    verifyLoader = DataLoader(verifyData, batch_size=BATCH_SIZE)
    del outData

    # å‡†å¤‡æ¨¡å‹å¯¹è±¡
    tqdm.write("å‡†å¤‡æ¨¡å‹...")
    model = Model(featureCount=len(inData[0][0]), predictLength=PREDICT_LENGTH)

    # è®­ç»ƒ
    tqdm.write("å¼€å§‹è®­ç»ƒ...")
    gc.collect()
    train(model, trainLoader, verifyLoader, EPOCHS, LOSS_RATE)
    del trainData, verifyData, trainLoader, verifyLoader

    # æ¨ç†
    tqdm.write("å¼€å§‹æ¨ç†...")
    gc.collect()
    print(predict(model, inData[-1]))


# èƒ½è®­ç»ƒäº†ï¼Œä½†é€Ÿåº¦åªæœ‰4it/sï¼Œè¿™å¾—è®­ç»ƒä¸€å¹´ã€‚
if __name__ == '__main__':
    main()
